# File: docker-compose.yml

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"           # Ollama API (internal+external for now)
    volumes:
      - ollama:/root/.ollama

  app:
    build:
      context: .
      args:
        BASE: "cpu"
    image: logs-train:cpu
    container_name: logs-train
    restart: unless-stopped
    env_file: .env
    environment:
      - PYTHONUNBUFFERED=1

      # Log ingestion LLM (host+model from .env)
      - LOG_LLM_HOST=${LOG_LLM_HOST}
      - LOG_LLM_MODEL=${LOG_LLM_MODEL}

      # NLâ†’SQL LLM (host+model from .env; future use)
      - SQL_LLM_HOST=${SQL_LLM_HOST}
      - SQL_LLM_MODEL=${SQL_LLM_MODEL}

      # Loader tuning
      - LOAD_VERBOSE=1
      - LOAD_TICK_SEC=1
      - LOAD_PROGRESS_EVERY=500

      # Streamlit default port
      - STREAMLIT_PORT=8501
    volumes:
      - ./src:/app/src
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./adapters:/app/adapters
      - ./docs:/app/docs
    ports:
      - "8501:8501"             # Streamlit UI (reserved; becomes active once UI is added)
    depends_on:
      - ollama

volumes:
  ollama: